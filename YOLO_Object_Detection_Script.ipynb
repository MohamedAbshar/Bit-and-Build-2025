{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedAbshar/Bit-and-Build-2025/blob/main/YOLO_Object_Detection_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "\n",
        "# --- 1. Download the Object Detection Dataset ---\n",
        "# We are downloading the TACO dataset, which is pre-formatted for YOLO object detection.\n",
        "# This means it already includes images, label files with bounding boxes, and a .yaml file.\n",
        "print(\"Downloading TACO object detection dataset...\")\n",
        "# Note: This is a different dataset specifically for detection.\n",
        "dataset_path = kagglehub.dataset_download(\"kneroma/tacotrashdataset\")\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading TACO object detection dataset...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kneroma/tacotrashdataset?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.79G/2.79G [01:37<00:00, 30.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/kneroma/tacotrashdataset/versions/3\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGZSFAexER2o",
        "outputId": "ffabed42-cb7e-484b-8c70-9b6df2d23b8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Define Paths for Conversion ---\n",
        "source_data_dir = os.path.join(dataset_path, 'data')\n",
        "annotations_path = os.path.join(source_data_dir, 'annotations.json')\n",
        "\n",
        "# Writable directory for our new YOLO-formatted dataset\n",
        "yolo_dataset_path = os.path.join('/kaggle/working', 'taco_yolo_dataset')\n",
        "\n",
        "# Define paths for the new structure\n",
        "images_path = os.path.join(yolo_dataset_path, 'images')\n",
        "labels_path = os.path.join(yolo_dataset_path, 'labels')\n",
        "train_images_path = os.path.join(images_path, 'train')\n",
        "val_images_path = os.path.join(images_path, 'val')\n",
        "train_labels_path = os.path.join(labels_path, 'train')\n",
        "val_labels_path = os.path.join(labels_path, 'val')\n"
      ],
      "metadata": {
        "id": "Ji1CNC9WEjuK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Create the YOLO Directory Structure ---\n",
        "print(\"\\n--- Step 2: Creating YOLO directory structure ---\")\n",
        "for path in [train_images_path, val_images_path, train_labels_path, val_labels_path]:\n",
        "    os.makedirs(path, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhDU00pgGvZv",
        "outputId": "432de949-ab5d-4716-d3f8-11dbfbf62619"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 2: Creating YOLO directory structure ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# --- Step 4: Load and Process Annotations ---\n",
        "print(\"\\n--- Step 3: Loading and processing annotations.json ---\")\n",
        "with open(annotations_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Create mappings\n",
        "images_info = {img['id']: img for img in coco_data['images']}\n",
        "categories_info = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "category_map = {cat['id']: i for i, cat in enumerate(coco_data['categories'])}\n",
        "class_names = [cat['name'] for cat in coco_data['categories']]\n",
        "\n",
        "# Group annotations by image_id\n",
        "annotations_by_image = {}\n",
        "for ann in coco_data['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    if img_id not in annotations_by_image:\n",
        "        annotations_by_image[img_id] = []\n",
        "    annotations_by_image[img_id].append(ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBg4IAAgG2_J",
        "outputId": "d7994e25-008f-4488-d847-5c45f2decbb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 3: Loading and processing annotations.json ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# --- Step 5: Split Data and Perform Conversion ---\n",
        "print(\"\\n--- Step 4: Splitting data and converting to YOLO format ---\")\n",
        "all_image_ids = list(images_info.keys())\n",
        "train_ids, val_ids = train_test_split(all_image_ids, test_size=0.2, random_state=42)\n",
        "\n",
        "def convert_and_move(image_ids, split_name):\n",
        "    image_dir = os.path.join(images_path, split_name)\n",
        "    label_dir = os.path.join(labels_path, split_name)\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        img_data = images_info[img_id]\n",
        "        file_name = img_data['file_name']\n",
        "        img_width = img_data['width']\n",
        "        img_height = img_data['height']\n",
        "\n",
        "        # Copy image file\n",
        "        source_img_path = os.path.join(source_data_dir, file_name)\n",
        "        if os.path.exists(source_img_path):\n",
        "            shutil.copy(source_img_path, os.path.join(image_dir, os.path.basename(file_name)))\n",
        "\n",
        "            # Create label file\n",
        "            label_file_path = os.path.join(label_dir, os.path.splitext(os.path.basename(file_name))[0] + '.txt')\n",
        "            with open(label_file_path, 'w') as f:\n",
        "                if img_id in annotations_by_image:\n",
        "                    for ann in annotations_by_image[img_id]:\n",
        "                        cat_id = ann['category_id']\n",
        "                        yolo_cat_id = category_map[cat_id]\n",
        "\n",
        "                        # Convert COCO bbox [x_min, y_min, width, height] to YOLO\n",
        "                        x_min, y_min, w, h = ann['bbox']\n",
        "                        x_center = (x_min + w / 2) / img_width\n",
        "                        y_center = (y_min + h / 2) / img_height\n",
        "                        norm_w = w / img_width\n",
        "                        norm_h = h / img_height\n",
        "\n",
        "                        f.write(f\"{yolo_cat_id} {x_center} {y_center} {norm_w} {norm_h}\\n\")\n",
        "\n",
        "print(\"Converting training data...\")\n",
        "convert_and_move(train_ids, 'train')\n",
        "print(\"Converting validation data...\")\n",
        "convert_and_move(val_ids, 'val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9slYq07zHjVn",
        "outputId": "0b70cd59-fffc-46b8-fb0d-f408e7cf55eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Splitting data and converting to YOLO format ---\n",
            "Converting training data...\n",
            "Converting validation data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Create the data.yaml File ---\n",
        "print(\"\\n--- Step 5: Creating the data.yaml file ---\")\n",
        "data_yaml_content = {\n",
        "    'train': train_images_path,\n",
        "    'val': val_images_path,\n",
        "    'nc': len(class_names),\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "data_yaml_path = os.path.join('/kaggle/working/', 'dataset.yaml')\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_yaml_content, f, default_flow_style=False)\n",
        "print(f\"data.yaml created at: {data_yaml_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGCsAxIsICVI",
        "outputId": "7bc5f9a1-b1da-483f-ecd8-1847f63a42e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 5: Creating the data.yaml file ---\n",
            "data.yaml created at: /kaggle/working/dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7: Load and Train the YOLO Model ---\n",
        "print(\"\\n--- Step 6: Loading and Training the Model ---\")\n",
        "model = YOLO('yolo12n.pt')\n",
        "\n",
        "print(\"Starting object detection model training...\")\n",
        "model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    project='taco_detection_project',\n",
        "    name='run1'\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJb2xEktIMXJ",
        "outputId": "13d1a7ac-c401-4d45-eb4e-868e68b38604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 6: Loading and Training the Model ---\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt': 100% ━━━━━━━━━━━━ 5.3MB 13.3MB/s 0.4s\n",
            "Starting object detection model training...\n",
            "Ultralytics 8.3.195 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=taco_detection_project, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/taco_detection_project/run1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 2.7MB/s 0.3s\n",
            "Overriding model.yaml nc=80 with nc=60\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    442372  ultralytics.nn.modules.head.Detect           [60, [64, 128, 256]]          \n",
            "YOLOv12n summary: 272 layers, 2,579,748 parameters, 2,579,732 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 640/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3188.2±640.3 MB/s, size: 1635.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/taco_yolo_dataset/labels/train... 316 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 316/316 1.1Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/taco_yolo_dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2935.7±504.9 MB/s, size: 1601.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/taco_yolo_dataset/labels/val... 182 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 182/182 1.6Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/taco_yolo_dataset/labels/val.cache\n",
            "Plotting labels to /content/taco_detection_project/run1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000156, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/taco_detection_project/run1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50         0G      1.407      5.527      1.407         88        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:11\n",
            "                   all        182        476          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50         0G      1.376      5.411      1.376         42        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:17\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:00\n",
            "                   all        182        476          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50         0G      1.445      5.329      1.395         33        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:10\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:06\n",
            "                   all        182        476          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50         0G      1.353      5.233      1.334         44        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:11\n",
            "                   all        182        476     0.0121     0.0185    0.00948    0.00905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50         0G      1.506      5.188      1.454         61        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:08\n",
            "                   all        182        476    0.00804     0.0919     0.0178     0.0167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50         0G      1.385      5.002      1.371         62        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:03\n",
            "                   all        182        476      0.604     0.0672     0.0336       0.03\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50         0G      1.423      4.871      1.378         70        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:06\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:02\n",
            "                   all        182        476      0.474     0.0855     0.0395     0.0352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50         0G      1.472      4.691      1.397         59        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:07\n",
            "                   all        182        476      0.565     0.0472     0.0224     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50         0G      1.524      4.722      1.459         60        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:09\n",
            "                   all        182        476      0.402     0.0314     0.0215     0.0183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50         0G      1.438      4.548      1.371         75        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:08\n",
            "                   all        182        476      0.569     0.0199     0.0264      0.022\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50         0G      1.462      4.533      1.382         51        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:13\n",
            "                   all        182        476      0.617     0.0215     0.0279      0.024\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50         0G      1.472      4.448       1.42         70        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:09\n",
            "                   all        182        476      0.526     0.0227       0.03     0.0261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50         0G      1.408      4.266      1.372         69        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:09\n",
            "                   all        182        476      0.315     0.0436     0.0326     0.0275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50         0G      1.441      4.212      1.403         72        640: 100% ━━━━━━━━━━━━ 20/20 0.1it/s 6:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:09\n",
            "                   all        182        476      0.364     0.0561       0.04     0.0339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50         0G       1.43      4.153      1.385         77        640: 60% ━━━━━━━───── 12/20 0.1it/s 4:01<2:32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 8: Export the Best Model ---\n",
        "print(\"\\n--- Step 7: Exporting the best model ---\")\n",
        "best_model_path = os.path.join('taco_detection_project', 'run1', 'weights', 'best.pt')\n",
        "destination_path = 'best_taco_detector.pt'\n",
        "if os.path.exists(best_model_path):\n",
        "    shutil.copy(best_model_path, destination_path)\n",
        "    print(f\"\\nModel saved successfully as '{destination_path}'\")\n",
        "else:\n",
        "    print(\"Could not find the best model file.\")"
      ],
      "metadata": {
        "id": "JxSQt-WzIbUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GzlO2bqCBNLn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}